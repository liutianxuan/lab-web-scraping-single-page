{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5989ccc5",
   "metadata": {},
   "source": [
    "**Lab | Web Scraping Single Page (GNOD part 1)**\n",
    "\n",
    "Business goal:\n",
    "Check the case_study_gnod.md file.\n",
    "\n",
    "Make sure you've understood the big picture of your project:\n",
    "\n",
    "the goal of the company (Gnod),\n",
    "their current product (Gnoosic),\n",
    "their strategy, and\n",
    "how your project fits into this context.\n",
    "Re-read the business case and the e-mail from the CTO.\n",
    "\n",
    "Instructions - Scraping popular songs\n",
    "Your product will take a song as an input from the user and will output another song (the recommendation). In most cases, the recommended song will have to be similar to the inputted song, but the CTO thinks that if the song is on the top charts at the moment, the user will also enjoy a recommendation of another song that is popular at the moment.\n",
    "\n",
    "You have to find data on the internet about currently popular songs. Popvortex maintains a weekly Top 100 of \"hot\" songs here: http://www.popvortex.com/music/charts/top-100-songs.php.\n",
    "\n",
    "It's a good place to start! Scrape the current top 100 songs and their respective artists, and put the information into a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbf56bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27ab01fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.popvortex.com/music/charts/top-100-songs.php'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "9fd9721a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = requests.get(url)\n",
    "response.status_code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b36f51ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "# soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "12799f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize empty lists\n",
    "title = []\n",
    "artist = []\n",
    "genre = []\n",
    "date = []\n",
    "\n",
    "\n",
    "# define the number of iterations of our for loop\n",
    "# by checking how many elements are in the retrieved result set\n",
    "# (this is equivalent but more robust than just explicitly defining 250 iterations)\n",
    "num_iter = len(soup.select(\"div.chart-content.col-xs-12.col-sm-8 > p\"))\n",
    "\n",
    "tlist = soup.select(\"div.chart-content.col-xs-12.col-sm-8 > p > cite\")\n",
    "alist = soup.select(\"div.chart-content.col-xs-12.col-sm-8 > p > em\")\n",
    "# iterate through the result set and retrive all the data\n",
    "for i in range(num_iter):\n",
    "    title.append(tlist[i].get_text())\n",
    "    artist.append(alist[i].get_text())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "bd9f0593",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>artist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fast Car</td>\n",
       "      <td>Luke Combs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Take Two</td>\n",
       "      <td>BTS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Last Night</td>\n",
       "      <td>Morgan Wallen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Need A Favor</td>\n",
       "      <td>Jelly Roll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>81 Million Votes, My Ass</td>\n",
       "      <td>The Truth Bombers &amp; Kari Lake</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      title                         artist\n",
       "0                  Fast Car                     Luke Combs\n",
       "1                  Take Two                            BTS\n",
       "2                Last Night                  Morgan Wallen\n",
       "3              Need A Favor                     Jelly Roll\n",
       "4  81 Million Votes, My Ass  The Truth Bombers & Kari Lake"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songs = pd.DataFrame({'title': title, 'artist': artist})\n",
    "songs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "45c6d1fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 2)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "9d2d73aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a song you like: Fast Car\n",
      "You might also like:  red flag collector\n"
     ]
    }
   ],
   "source": [
    "song = input('Enter a song you like: ')\n",
    "if song in songs.title.to_list():\n",
    "    print('You might also like: ', random.choice(songs.title))\n",
    "else:\n",
    "    print('Try a different song.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49e11a4",
   "metadata": {},
   "source": [
    "**Lab | Web Scraping Multiple Pages**\n",
    "Business goal:\n",
    "Check the case_study_gnod.md file.\n",
    "\n",
    "Expand the project\n",
    "If you're done, you can try to expand the project on your own. Here are a few suggestions:\n",
    "\n",
    "Find other lists of hot songs on the internet and scrape them too: having a bigger pool of songs will be awesome!\n",
    "Apply the same logic to other \"groups\" of songs: the best songs from a decade or from a country / culture / language / genre.\n",
    "Wikipedia maintains a large collection of lists of songs: https://en.wikipedia.org/wiki/Lists_of_songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f747ff01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://www.billboard.com/charts/hot-100/'\n",
    "response = requests.get(url)\n",
    "response.status_code \n",
    "# soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "# soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "6d3fb38c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>artist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Last Night</td>\n",
       "      <td>Morgan Wallen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Karma</td>\n",
       "      <td>Taylor Swift Featuring Ice Spice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Flowers</td>\n",
       "      <td>Miley Cyrus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>All My Life</td>\n",
       "      <td>Lil Durk Featuring J. Cole</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Calm Down</td>\n",
       "      <td>Rema &amp; Selena Gomez</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         title                            artist\n",
       "0   Last Night                     Morgan Wallen\n",
       "1        Karma  Taylor Swift Featuring Ice Spice\n",
       "2      Flowers                       Miley Cyrus\n",
       "3  All My Life        Lil Durk Featuring J. Cole\n",
       "4    Calm Down               Rema & Selena Gomez"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title = []\n",
    "artist = []\n",
    "\n",
    "result = soup.find_all('div', class_='o-chart-results-list-row-container')\n",
    "for i in result:\n",
    "    title.append(i.find('h3').text.strip())\n",
    "    artist.append(i.find('h3').find_next('span').text.strip())\n",
    "\n",
    "\n",
    "billboard = pd.DataFrame({'title': title, 'artist': artist})\n",
    "billboard.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "509f80ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 2)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "billboard.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "88a714ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a song you like: Calm Down\n",
      "You might also like:  Wild Thing\n"
     ]
    }
   ],
   "source": [
    "song = input('Enter a song you like: ')\n",
    "if song in billboard.title.to_list():\n",
    "    print('You might also like: ', random.choice(songs.title))\n",
    "else:\n",
    "    print('Try a different song.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552672e8",
   "metadata": {},
   "source": [
    "Instructions Part 2\n",
    "Practice web scraping. This is not involved with the GNOD project of the week\n",
    "As you've seen, scraping the internet is a skill that can get you all sorts of information. Here are some little challenges that you can try to gain more experience in the field. Open a new Jupyter notebook and scrape at least 3 of these sites.\n",
    "\n",
    "1. Retrieve an arbitrary Wikipedia page of \"Python\" and create a list of links on that page: url ='https://en.wikipedia.org/wiki/Python'\n",
    "2. Find the number of titles that have changed in the United States Code since its last release point: url = 'http://uscode.house.gov/download/download.shtml'\n",
    "3. Create a Python list with the top ten FBI's Most Wanted names: url = 'https://www.fbi.gov/wanted/topten'\n",
    "4. Display the 20 latest earthquakes info (date, time, latitude, longitude and region name) by the EMSC as a pandas dataframe: url = 'https://www.emsc-csem.org/Earthquake/'\n",
    "5. List all language names and number of related articles in the order they appear in wikipedia.org: url = 'https://www.wikipedia.org/'\n",
    "6. A list with the different kind of datasets available in data.gov.uk: url = 'https://data.gov.uk/'\n",
    "Display the top 10 languages by number of native speakers stored in a pandas dataframe: url = 'https://en.wikipedia.org/wiki/List_of_languages_by_number_of_native_speakers'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb922ca",
   "metadata": {},
   "source": [
    "**Retrieve an arbitrary Wikipedia page of \"Python\" and create a list of links on that page**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e8c0ddb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://en.wikipedia.org/wiki/Python'\n",
    "response = requests.get(url)\n",
    "response.status_code \n",
    "# soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "response = requests.get(url)\n",
    "response.status_code \n",
    "# soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "# soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "d8cf3a6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://en.wiktionary.org/wiki/Python',\n",
       " 'https://en.wiktionary.org/wiki/python',\n",
       " '/w/index.php?title=Python&action=edit&section=1',\n",
       " '/wiki/Pythonidae',\n",
       " '/wiki/Python_(genus)',\n",
       " '/wiki/Python_(mythology)',\n",
       " '/w/index.php?title=Python&action=edit&section=2',\n",
       " '/wiki/Python_(programming_language)',\n",
       " '/wiki/CMU_Common_Lisp',\n",
       " '/wiki/PERQ#PERQ_3',\n",
       " '/w/index.php?title=Python&action=edit&section=3',\n",
       " '/wiki/Python_of_Aenus',\n",
       " '/wiki/Python_(painter)',\n",
       " '/wiki/Python_of_Byzantium',\n",
       " '/wiki/Python_of_Catana',\n",
       " '/wiki/Python_Anghelo',\n",
       " '/w/index.php?title=Python&action=edit&section=4',\n",
       " '/wiki/Python_(Efteling)',\n",
       " '/wiki/Python_(Busch_Gardens_Tampa_Bay)',\n",
       " '/wiki/Python_(Coney_Island,_Cincinnati,_Ohio)',\n",
       " '/w/index.php?title=Python&action=edit&section=5',\n",
       " '/wiki/Python_(automobile_maker)',\n",
       " '/wiki/Python_(Ford_prototype)',\n",
       " '/w/index.php?title=Python&action=edit&section=6',\n",
       " '/wiki/Python_(missile)',\n",
       " '/wiki/Python_(nuclear_primary)',\n",
       " '/wiki/Colt_Python',\n",
       " '/w/index.php?title=Python&action=edit&section=7',\n",
       " '/wiki/Python_(codename)',\n",
       " '/wiki/Python_(film)',\n",
       " '/wiki/Monty_Python',\n",
       " '/wiki/Python_(Monty)_Pictures',\n",
       " '/wiki/Timon_of_Phlius',\n",
       " '/w/index.php?title=Python&action=edit&section=8',\n",
       " '/wiki/Pyton',\n",
       " '/wiki/Pithon',\n",
       " '/wiki/File:Disambig_gray.svg',\n",
       " '/wiki/Help:Disambiguation',\n",
       " 'https://en.wikipedia.org/w/index.php?title=Special:WhatLinksHere/Python&namespace=0']"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "link = []\n",
    "\n",
    "llist = soup.select('#mw-content-text > div.mw-parser-output a')\n",
    "\n",
    "for i in llist:\n",
    "    url = i.get('href', '')\n",
    "    link.append(url)\n",
    "\n",
    "link"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc9c730",
   "metadata": {},
   "source": [
    "**Create a Python list with the top ten FBI's Most Wanted names**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "994618b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://www.fbi.gov/wanted/topten'\n",
    "response = requests.get(url)\n",
    "response.status_code \n",
    "# soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "response = requests.get(url)\n",
    "response.status_code \n",
    "# soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "# soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "ab00add1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a href=\"https://www.fbi.gov/wanted/topten/ruja-ignatova\">RUJA IGNATOVA</a>,\n",
       " <a href=\"https://www.fbi.gov/wanted/topten/donald-eugene-fields-ii\">DONALD EUGENE FIELDS II</a>,\n",
       " <a href=\"https://www.fbi.gov/wanted/topten/arnoldo-jimenez\">ARNOLDO JIMENEZ</a>,\n",
       " <a href=\"https://www.fbi.gov/wanted/topten/omar-alexander-cardenas\">OMAR ALEXANDER CARDENAS</a>,\n",
       " <a href=\"https://www.fbi.gov/wanted/topten/alexis-flores\">ALEXIS FLORES</a>,\n",
       " <a href=\"https://www.fbi.gov/wanted/topten/yulan-adonay-archaga-carias\">YULAN ADONAY ARCHAGA CARIAS</a>,\n",
       " <a href=\"https://www.fbi.gov/wanted/topten/bhadreshkumar-chetanbhai-patel\">BHADRESHKUMAR CHETANBHAI PATEL</a>,\n",
       " <a href=\"https://www.fbi.gov/wanted/topten/wilver-villegas-palomino\">WILVER VILLEGAS-PALOMINO</a>,\n",
       " <a href=\"https://www.fbi.gov/wanted/topten/alejandro-castillo\">ALEJANDRO ROSALES CASTILLO</a>,\n",
       " <a href=\"https://www.fbi.gov/wanted/topten/jose-rodolfo-villarreal-hernandez\">JOSE RODOLFO VILLARREAL-HERNANDEZ</a>]"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.select('h3 > a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "39e3e4f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RUJA IGNATOVA',\n",
       " 'DONALD EUGENE FIELDS II',\n",
       " 'ARNOLDO JIMENEZ',\n",
       " 'OMAR ALEXANDER CARDENAS',\n",
       " 'ALEXIS FLORES',\n",
       " 'YULAN ADONAY ARCHAGA CARIAS',\n",
       " 'BHADRESHKUMAR CHETANBHAI PATEL',\n",
       " 'WILVER VILLEGAS-PALOMINO',\n",
       " 'ALEJANDRO ROSALES CASTILLO',\n",
       " 'JOSE RODOLFO VILLARREAL-HERNANDEZ']"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names = []\n",
    "\n",
    "nlist = soup.select('h3 > a')\n",
    "num_iter = len(nlist)\n",
    "\n",
    "for i in range(num_iter):\n",
    "    names.append(nlist[i].get_text())\n",
    "    \n",
    "names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce4af6d",
   "metadata": {},
   "source": [
    "**List all language names and number of related articles in the order they appear in wikipedia.org**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18a23369",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "url = 'https://www.wikipedia.org/'\n",
    "response = requests.get(url)\n",
    "display(response.status_code)\n",
    "# soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "response = requests.get(url)\n",
    "display(response.status_code)\n",
    "# soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "# soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "5445b066",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<strong>English</strong>,\n",
       " <strong>日本語</strong>,\n",
       " <strong>Español</strong>,\n",
       " <strong>Русский</strong>,\n",
       " <strong>Deutsch</strong>,\n",
       " <strong>Français</strong>,\n",
       " <strong>Italiano</strong>,\n",
       " <strong>中文</strong>,\n",
       " <strong><bdi dir=\"rtl\">فارسی</bdi></strong>,\n",
       " <strong>Português</strong>]"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.select('div > a > strong')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "262d5a37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<bdi dir=\"ltr\">6 668 000+</bdi>,\n",
       " <bdi dir=\"ltr\">1 376 000+</bdi>,\n",
       " <bdi dir=\"ltr\">1 869 000+</bdi>,\n",
       " <bdi dir=\"ltr\">1 921 000+</bdi>,\n",
       " <bdi dir=\"ltr\">2 808 000+</bdi>,\n",
       " <bdi dir=\"ltr\">2 528 000+</bdi>,\n",
       " <bdi dir=\"ltr\">1 814 000+</bdi>,\n",
       " <bdi dir=\"ltr\">1 360 000+</bdi>,\n",
       " <bdi dir=\"ltr\">965 000+</bdi>,\n",
       " <bdi dir=\"ltr\">1 103 000+</bdi>]"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.select('div > a > small > bdi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "cb719516",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>numArticles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>English</td>\n",
       "      <td>6 668 000+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>日本語</td>\n",
       "      <td>1 376 000+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Español</td>\n",
       "      <td>1 869 000+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Русский</td>\n",
       "      <td>1 921 000+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Deutsch</td>\n",
       "      <td>2 808 000+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Français</td>\n",
       "      <td>2 528 000+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Italiano</td>\n",
       "      <td>1 814 000+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>中文</td>\n",
       "      <td>1 360 000+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>فارسی</td>\n",
       "      <td>965 000+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Português</td>\n",
       "      <td>1 103 000+</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    language numArticles\n",
       "0    English  6 668 000+\n",
       "1        日本語  1 376 000+\n",
       "2    Español  1 869 000+\n",
       "3    Русский  1 921 000+\n",
       "4    Deutsch  2 808 000+\n",
       "5   Français  2 528 000+\n",
       "6   Italiano  1 814 000+\n",
       "7         中文  1 360 000+\n",
       "8      فارسی    965 000+\n",
       "9  Português  1 103 000+"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "languages = []\n",
    "articles = []\n",
    "\n",
    "lanlist = soup.select('div > a > strong')\n",
    "artlist = soup.select('div > a > small > bdi')\n",
    "\n",
    "num_iter = len(lanlist)\n",
    "\n",
    "for i in range(num_iter):\n",
    "    languages.append(lanlist[i].get_text())\n",
    "    articles.append(artlist[i].get_text())\n",
    "    \n",
    "wiki = pd.DataFrame({'language': languages, 'numArticles': articles})\n",
    "wiki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140c2982",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7886cf2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d58d35e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
